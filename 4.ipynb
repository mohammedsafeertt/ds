{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wSG1ss6ri5-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class RandomForest:\n",
        "    def __init__(self, num_trees=100, max_depth=None, max_features='sqrt', random_seed=None):\n",
        "        \"\"\"\n",
        "        Initializes a Random Forest classifier.\n",
        "\n",
        "        Parameters:\n",
        "        - num_trees: Number of decision trees in the forest\n",
        "        - max_depth: Maximum depth allowed for each decision tree\n",
        "        - max_features: Strategy for feature selection at each split:\n",
        "                       'sqrt' - square root of total features\n",
        "                       int - exact number of features\n",
        "                       None - all features\n",
        "        - random_seed: Seed for random number generation (for reproducibility)\n",
        "        \"\"\"\n",
        "        self.num_trees = num_trees\n",
        "        self.max_depth = max_depth\n",
        "        self.max_features = max_features\n",
        "        self.random_seed = random_seed\n",
        "        self.decision_trees = []  # List to store all decision trees\n",
        "        self.selected_features = []  # Features used for each corresponding tree\n",
        "\n",
        "    def fit(self, features, targets):\n",
        "        \"\"\"\n",
        "        Trains the Random Forest model on the provided dataset.\n",
        "\n",
        "        Parameters:\n",
        "        - features: Input feature matrix (num_samples × num_features)\n",
        "        - targets: Target values (num_samples,)\n",
        "        \"\"\"\n",
        "        np.random.seed(self.random_seed)\n",
        "        num_samples, num_features = features.shape\n",
        "\n",
        "        # Determine how many features to consider at each split\n",
        "        if self.max_features == 'sqrt':\n",
        "            features_per_split = int(np.sqrt(num_features))\n",
        "        elif isinstance(self.max_features, int):\n",
        "            features_per_split = self.max_features\n",
        "        else:\n",
        "            features_per_split = num_features\n",
        "\n",
        "        self.decision_trees = []\n",
        "        self.selected_features = []\n",
        "\n",
        "        for _ in range(self.num_trees):\n",
        "            # Create bootstrap sample (with replacement)\n",
        "            bootstrapped_features, bootstrapped_targets = resample(\n",
        "                features, targets, random_state=self.random_seed\n",
        "            )\n",
        "\n",
        "            # Randomly select subset of features\n",
        "            feature_subset = np.random.choice(\n",
        "                num_features, features_per_split, replace=False\n",
        "            )\n",
        "            bootstrapped_features = bootstrapped_features[:, feature_subset]\n",
        "\n",
        "            # Train a decision tree on the bootstrap sample\n",
        "            tree = DecisionTreeClassifier(\n",
        "                max_depth=self.max_depth,\n",
        "                random_state=self.random_seed\n",
        "            )\n",
        "            tree.fit(bootstrapped_features, bootstrapped_targets)\n",
        "\n",
        "            # Store the trained tree and its feature subset\n",
        "            self.decision_trees.append(tree)\n",
        "            self.selected_features.append(feature_subset)\n",
        "\n",
        "    def predict_proba(self, features):\n",
        "        \"\"\"\n",
        "        Predicts class probabilities by averaging predictions from all trees.\n",
        "\n",
        "        Parameters:\n",
        "        - features: Input feature matrix (num_samples × num_features)\n",
        "\n",
        "        Returns:\n",
        "        - probabilities: Array (num_samples × num_classes) with class probabilities\n",
        "        \"\"\"\n",
        "        num_samples = features.shape[0]\n",
        "        all_probabilities = []\n",
        "\n",
        "        for tree, features_used in zip(self.decision_trees, self.selected_features):\n",
        "            # Use only the features this particular tree was trained on\n",
        "            subset_features = features[:, features_used]\n",
        "            tree_probabilities = tree.predict_proba(subset_features)\n",
        "            all_probabilities.append(tree_probabilities)\n",
        "\n",
        "        # Calculate average probabilities across all trees\n",
        "        average_probabilities = np.mean(all_probabilities, axis=0)\n",
        "        return average_probabilities\n",
        "\n",
        "    def predict(self, features):\n",
        "        \"\"\"\n",
        "        Predicts class labels using majority voting from all trees.\n",
        "\n",
        "        Parameters:\n",
        "        - features: Input feature matrix (num_samples × num_features)\n",
        "\n",
        "        Returns:\n",
        "        - predictions: Array (num_samples,) with predicted class labels\n",
        "        \"\"\"\n",
        "        probabilities = self.predict_proba(features)\n",
        "        return np.argmax(probabilities, axis=1)\n",
        "\n",
        "# Demonstration of usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load the iris dataset\n",
        "    iris_data = load_iris()\n",
        "    X, y = iris_data.data, iris_data.target\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Random Forest model\n",
        "    forest = RandomForest(num_trees=100, max_depth=3, random_seed=42)\n",
        "    forest.fit(X_train, y_train)\n",
        "\n",
        "    # Generate predictions on test set\n",
        "    predictions = forest.predict(X_test)\n",
        "\n",
        "    # Calculate and display accuracy\n",
        "    model_accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f\"Random Forest Accuracy: {model_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuJbw2wSCoXu",
        "outputId": "25eee187-971a-4740-ba8c-c13c08e8feec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9667\n"
          ]
        }
      ]
    }
  ]
}